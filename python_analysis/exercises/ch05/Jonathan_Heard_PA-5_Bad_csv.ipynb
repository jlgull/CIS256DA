{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc974d5-08c8-43bd-8c30-aab1c88a757e",
   "metadata": {},
   "source": [
    "# Project Assignment 5 - Get different types of data \n",
    "## Author: Jonathan Heard\n",
    "## Class: CIS256DA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e6322-e007-4ace-b9b7-f44104dab4e1",
   "metadata": {},
   "source": [
    "Chapter 5 Asignment\n",
    "\n",
    "Search KaggleLinks to an external site. for something that you are interested in to see if there is any datasets related to that interest. If there is, download that dataset.  If not, just download one of the trending datasets in the trending section as shown below (2 pts.):\n",
    "\n",
    "Tasks\n",
    "\n",
    "1. Read the data from the CSV file into a DataFrame (2 pts.).\n",
    "2. Display the first five rows of data (2 pts.).\n",
    "3. Display information about each of the columns (2 pts.).\n",
    "\n",
    "Question\n",
    "\n",
    "Why did you choose the downloaded dataset (2 pts.)?\n",
    "\n",
    "\n",
    "After completing the assignment, please submit your .ipynb file and the dataset you downloaded from Kaggle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca876ef-4634-4a78-918d-d63eae58cfc2",
   "metadata": {},
   "source": [
    "### The url for the site the data came from is:\n",
    "\n",
    "https://www.kaggle.com/datasets/taruntiwarihp/phishing-site-urls\n",
    "\n",
    "The download was a 9 MB zip file, \n",
    "    called \"Malicious_and_Phishing_attacks_ulrs_archive.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6c4f7-dc2d-4981-8033-5f49e1cddc07",
   "metadata": {},
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f2a02a-ff69-47ab-acf0-f2971cf78a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules needed for this project.\n",
    "\n",
    "# Import pandas and assign the alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Import ZipFile from the zipfile module\n",
    "from zipfile import ZipFile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd65f6-1414-4318-952c-34157e13aafd",
   "metadata": {},
   "source": [
    "## Tasks list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2207dd8-40b8-40ae-8d17-37cb93b742fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dionaeaClean2.csv 272666 2042298\n"
     ]
    }
   ],
   "source": [
    "# Extract the files from the zip file and diplsy the file names\n",
    "\n",
    "file_names = list()\n",
    "with ZipFile('HoneyPots_archive.zip', mode = 'r') as zip:\n",
    "    zip.extractall()\n",
    "    for file in zip.infolist():\n",
    "        file_names.append(file.filename)\n",
    "        print(file.filename, file.compress_size, file.file_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0be4ba-6962-416e-bb8e-6440e6d0e5fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 8 fields in line 2026, saw 10\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Task 01 Read the data from the CSV file into a DataFrame (2 pts.).\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m phishing \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdionaeaClean2.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1255\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1253\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1255\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 8 fields in line 2026, saw 10\n"
     ]
    }
   ],
   "source": [
    "# Task 01 Read the data from the CSV file into a DataFrame (2 pts.).\n",
    "\n",
    "phishing = pd.read_csv('dionaeaClean2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90adac-fd15-464e-afd7-88d8a42b3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 02 Display the first five rows of data (2 pts.).\n",
    "\n",
    "phishing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658f32b-b593-43cb-b145-adb59934af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 03 Display information about each of the columns (2 pts.).\n",
    "\n",
    "phishing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c539f6-2bc8-4b47-b9f0-b69c9a48812f",
   "metadata": {},
   "source": [
    "## Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d46eb0-ffa6-4362-8108-5f4ecc47f017",
   "metadata": {},
   "source": [
    "### Example of the problem I found, related to what I am calling bad csv files.\n",
    "\n",
    "The \"bad\" csv files I tried, prior to my success, all generated long set of error messages that I could not \n",
    "    understand. I even went back to the Exercise 1 csv, just to prove my code was working.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d191f-9f07-43a9-9f12-cabee656f2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
